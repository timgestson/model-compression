{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If training in collab\n",
    "! pip install cloud-tpu-client https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.13-cp38-cp38m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lightning tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
    "    transforms.ToTensor\n",
    "])\n",
    "\n",
    "\n",
    "teacher_train_set = MNIST(os.getcwd(), download=True, train=True, transform=tfs)\n",
    "student_train_set = MNIST(os.getcwd(), download=True, train=True, transform=transforms.ToTensor())\n",
    "test_set = MNIST(os.getcwd(), download=True, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_set_size = int(len(teacher_train_set) * 0.8)\n",
    "valid_set_size = len(teacher_train_set) - train_set_size\n",
    "\n",
    "# split the train set into two\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = data.random_split(teacher_train_set, [train_set_size, valid_set_size], generator=seed)\n",
    "train_loader = DataLoader(train_set)\n",
    "validation_loader = DataLoader(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teacher import MnistTeacher as Teacher\n",
    "from student import MnistStudent as Student\n",
    "from distillation import Distillation as Distiller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: tb_logs/teacher\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | net  | Sequential | 2.4 M \n",
      "------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.581     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/pytorch-lightning/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/pytorch-lightning/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  86%|████████▌ | 41352/48000 [33:30<05:23, 20.56it/s, v_num=0]"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "# model\n",
    "teacher = Teacher()\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "            logger=TensorBoardLogger(\"tb_logs\", name=\"teacher\"),\n",
    "            max_epochs=10\n",
    "        )\n",
    "trainer.fit(teacher, train_loader, validation_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiller = Distiller()\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "            logger=TensorBoardLogger(\"tb_logs\", name=\"teacher\"),\n",
    "            max_epochs=10\n",
    "        )\n",
    "trainer.fit(model=distiller, train_dataloaders=train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
